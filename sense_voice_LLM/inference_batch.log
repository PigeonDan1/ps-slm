[2025-07-30 15:08:54,342][root][INFO] - train_config: {'model_name': 'ps-slm', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': None, 'batching_strategy': 'dynamic', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'num_workers_dataloader': 0, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': None, 'do_psd': True, 'ctc_posterior': True, 'voca_trans': True, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 64, 'lora_alpha': 16, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': False, 'device': 3}
[2025-07-30 15:08:54,343][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.SHARD_GRAD_OP: 2>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-07-30 15:08:54,343][root][INFO] - model_config: {'file': 'model/ps-slm.py:model_factory', 'llm_name': 'Qwen2.5-7B-Instruct', 'llm_path': '/aistor/aispeech/hpc_stor01/home/fangyangui/workingspace/model/Qwen2.5-1.5B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 151936, 'encoder_name': 'sensevoice', 'encoder_config': {'input_size': 80, 'activation_type': 'swish', 'attention_dropout_rate': 0.0, 'attention_heads': 12, 'cnn_module_kernel': 33, 'cnn_module_norm': 'layer_norm', 'dropout_rate': 0.1, 'input_layer': 'conv2d', 'linear_units': 3584, 'normalize_before': True, 'num_blocks': 16, 'output_size': 768, 'pos_enc_layer_type': 'rel_pos', 'positional_dropout_rate': 0.1, 'selfattention_layer_type': 'rel_selfattn', 'use_cnn_module': True}, 'encoder_path': '/aistor/aispeech/hpc_stor01/group/asr/model/SenseVoiceSmall', 'encoder_dim': 512, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 1, 'ctc_linear': '/aistor/aispeech/hpc_stor01/home/pengjing00sx/Github/ps-slm/ps-ctc/exp_sensevoice_librispeech_qwen_frozen/step_10000.pt'}
[2025-07-30 15:08:58,306][utils.model_utils][INFO] - --> Module Qwen2.5-7B-Instruct
[2025-07-30 15:08:58,309][utils.model_utils][INFO] - --> Qwen2.5-7B-Instruct has 1543.714304 Million params

[2025-07-30 15:08:58,310][utils.model_utils][INFO] - --> Module Qwen2.5-7B-Instruct
[2025-07-30 15:08:58,312][utils.model_utils][INFO] - --> Qwen2.5-7B-Instruct has 1543.714304 Million params

[2025-07-30 15:09:06,474][root][INFO] - download models from model hub: ms
[2025-07-30 15:09:09,717][root][INFO] - Loading pretrained params from /aistor/aispeech/hpc_stor01/group/asr/model/SenseVoiceSmall/model.pt
[2025-07-30 15:09:09,729][root][INFO] - ckpt: /aistor/aispeech/hpc_stor01/group/asr/model/SenseVoiceSmall/model.pt
[2025-07-30 15:09:11,235][root][INFO] - scope_map: ['module.', 'None']
[2025-07-30 15:09:11,236][root][INFO] - excludes: None
[2025-07-30 15:09:11,459][root][INFO] - Loading ckpt: /aistor/aispeech/hpc_stor01/group/asr/model/SenseVoiceSmall/model.pt, status: <All keys matched successfully>
[2025-07-30 15:09:15,507][ps-slm.py][INFO] - loading other parts from: /pytorch_model.bin
